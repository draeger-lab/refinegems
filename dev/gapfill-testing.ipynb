{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brune/miniconda3/envs/sprg/lib/python3.10/site-packages/pydantic/_internal/_config.py:322: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in debugging mode.\n"
     ]
    }
   ],
   "source": [
    "from refinegems.classes.gapfill import GeneGapFiller\n",
    "from refinegems.utility.io import load_model\n",
    "\n",
    "modelpath = '/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/JSC1435/JCSC1435.xml'\n",
    "model = load_model(modelpath,'libsbml')\n",
    "cmodel = load_model(modelpath,'cobra')\n",
    "\n",
    "gffpath = '/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/JSC1435/JCSC1435_RefSeq.gff'\n",
    "\n",
    "gf2 = GeneGapFiller()\n",
    "gf2_missing_genes = gf2.get_missing_genes(gffpath,model)\n",
    "# ncbiprotein | locus_tag | ec-code\n",
    "\n",
    "tfasta = '/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/JSC1435/JCSC1435_proteins_genome.fasta'\n",
    "spdb = '/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/swissprot.dmnd'\n",
    "# gf2_missing_genes\n",
    "spmap = '/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/uniprot_table.tsv'\n",
    "kwargs = {'outdir':'/Users/brune/Documents/11_Test_Data/test_refinegems/test_gapfill/JSC1435',\n",
    "          'sens':'more-sensitive',\n",
    "          'cov':90.0,\n",
    "          't':4,\n",
    "          'pid':90.0}\n",
    "\n",
    "mapped_res = gf2.get_missing_reacs(model=cmodel,\n",
    "                                   missing_genes=gf2_missing_genes,\n",
    "                                   fasta=tfasta, \n",
    "                                   dmnd_db=spdb,\n",
    "                                   swissprot_map=spmap,\n",
    "                                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the \"Filling\" part of Gapfilling\n",
    "\n",
    "**input**\n",
    "\n",
    "- the model\n",
    "- missing genes table\n",
    "- missing reacs table\n",
    "\n",
    "**out**\n",
    "\n",
    "- the extended model\n",
    "\n",
    "**else**\n",
    "\n",
    "- logging\n",
    "- save stats information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import re\n",
    "from refinegems.utility.cvterms import add_cv_term_genes\n",
    "from libsbml import FbcOr, FbcAnd, GeneProductRef\n",
    "import warnings\n",
    "\n",
    "\n",
    "# @TODO merge with the function of the same name in entities, if possible\n",
    "# or just use them separatly \n",
    "# @TODO generalise addition of references -> maybe kwargs\n",
    "# @TODO\n",
    "# what to do about the name\n",
    "def create_gp(model, protein_id, \n",
    "              name:str=None, locus_tag:str=None,\n",
    "              uniprot:tuple[str,bool]=None):\n",
    "    \n",
    "    # create gene product object\n",
    "    gp = model.getPlugin(0).createGeneProduct()\n",
    "    # set basic attributes\n",
    "    geneid = f'G_{protein_id}'.replace('.','_') # remove problematic signs\n",
    "    gp.setIdAttribute(geneid)               # ID \n",
    "    if name: gp.setName(name)               # Name  \n",
    "    if locus_tag: gp.setLabel(locus_tag)    # Label\n",
    "    gp.setSBOTerm('SBO:0000243')            # SBOterm\n",
    "    gp.setMetaId(f'meta_G_{protein_id}')    # Meta ID\n",
    "    # test for NCBI/RefSeq\n",
    "    if re.fullmatch('^(((AC|AP|NC|NG|NM|NP|NR|NT|NW|WP|XM|XP|XR|YP|ZP)_\\d+)|(NZ_[A-Z]{2,4}\\d+))(\\.\\d+)?$', protein_id, re.IGNORECASE):\n",
    "        id_db = 'REFSEQ'\n",
    "    elif re.fullmatch('^(\\w+\\d+(\\.\\d+)?)|(NP_\\d+)$', protein_id, re.IGNORECASE): id_db = 'NCBI'\n",
    "    if id_db: add_cv_term_genes(protein_id, id_db, gp)           # NCBI protein\n",
    "    # add further references\n",
    "    # @TODO extend or generalise\n",
    "    if uniprot:\n",
    "        for uniprotid in uniprot[0]:\n",
    "            add_cv_term_genes(uniprotid, 'UNIPROT', gp, uniprot[1]) # UniProt\n",
    "   \n",
    "   \n",
    "# probably sort into GapFiller\n",
    "def add_genes_from_table(model, gene_table:pd.DataFrame):\n",
    "    \n",
    "    # ncbiprotein | locus_tag | ec-code | ...\n",
    "    # work on a copy to ensure input stays the same\n",
    "    gene_table = gene_table.copy()\n",
    "    gene_table.drop(columns=['ec-code'],inplace=True)\n",
    "    \n",
    "    # create gps from the table and add them to the model\n",
    "    for idx,x in gene_table.iterrows():\n",
    "        create_gp(model, x['ncbiprotein'], \n",
    "                  locus_tag=x['locus_tag'],\n",
    "                  uniprot=(x['UniProt'],True))\n",
    "        \n",
    "\n",
    "# @TODO : does it cover indeed all cases\n",
    "# Where to sort it -> entities?\n",
    "def create_gpr(reaction,gene):\n",
    "\n",
    "    # Step 1: test, if there is already a gpr\n",
    "    # ---------------------------------------\n",
    "    old_association_str = None\n",
    "    old_association_fbc = None\n",
    "    if reaction.getPlugin(0).getGeneProductAssociation():\n",
    "        old_association = reaction.getPlugin(0).getGeneProductAssociation().getListOfAllElements()\n",
    "        # case 1: only a single association\n",
    "        if len(old_association) == 1 and isinstance(old_association[0],GeneProductRef):\n",
    "            old_association_str = old_association[0].getGeneProduct()\n",
    "        # case 2: nested structure of asociations\n",
    "        elif isinstance(old_association[0], FbcOr) or isinstance(old_association[0], FbcAnd):\n",
    "            old_association_fbc = old_association[0].clone()\n",
    "            # this should get the highest level association (that includes all others)\n",
    "\n",
    "                    \n",
    "    # Step 2: create new gene product association \n",
    "    # -------------------------------------------\n",
    "    if old_association_str and isinstance(gene,str):\n",
    "        gene = [old_association_str,id]\n",
    "    elif old_association_str  and isinstance(gene,list):\n",
    "        gene.append(old_association_str)\n",
    "        \n",
    "    # add the old association rule as an 'OR' (if needed)\n",
    "    if not old_association_fbc:\n",
    "        new_association = reaction.getPlugin(0).createGeneProductAssociation()\n",
    "    else:\n",
    "        new_association = reaction.getPlugin(0).createGeneProductAssociation().createOr()\n",
    "        new_association.addAssociation(old_association_fbc)\n",
    "\n",
    "    # add the remaining genes \n",
    "    # @TODO currently, only connection possible is 'OR'\n",
    "    if isinstance(gene,str):\n",
    "        new_association.createGeneProductRef().setGeneProduct(gene)\n",
    "    elif isinstance(gene,list) and len(gene) == 1:\n",
    "        new_association.createGeneProductRef().setGeneProduct(gene[0])\n",
    "    elif isinstance(gene,list) and len(gene) > 1:\n",
    "        gpa_or =  new_association.createOr()\n",
    "        for i in gene:\n",
    "            gpa_or.createGeneProductRef().setGeneProduct(i)\n",
    "            \n",
    "\n",
    "# @TODO seems very ridgid, beter ways to find the ids?\n",
    "# probably sort into GapFiller\n",
    "def add_gene_reac_associations_from_table(model,reac_table:pd.DataFrame):\n",
    "    \n",
    "    model_gene_ids = [_.getId() for _ in model.getPlugin(0).getListOfGeneProducts()]\n",
    "    \n",
    "    # get each unique ncbiprotein vs reaction mapping\n",
    "    reac_table = reac_table[['ncbiprotein','add_to_GPR']]\n",
    "    reac_table = reac_table.explode('ncbiprotein').explode('add_to_GPR')\n",
    "    reac_table.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # add the genes to the corresponding GPRs\n",
    "    for idx,row in reac_table.iterrows():\n",
    "        # check, if G_+ncbiprotein in model\n",
    "        # if yes, add gpr\n",
    "        geneid = 'G_'+row['ncbiprotein'].replace('.','_')\n",
    "        reacid = 'R_'+row['add_to_GPR']\n",
    "        if geneid in model_gene_ids:\n",
    "            create_gpr(model.getReaction(reacid),geneid)\n",
    "         # else, print warning\n",
    "        else:\n",
    "            mes = f'Cannot find {geneid} in model. Should be added to {reacid}'\n",
    "            warnings.warn(mes,UserWarning)\n",
    "    \n",
    "\n",
    "def fill_model(model, missing_genes:pd.DataFrame, \n",
    "               missing_reacs:pd.DataFrame):\n",
    "    \n",
    "    # Step 1: Add genes to model whoose reactions are already in it\n",
    "    # -------------------------------------------------------------\n",
    "    # filter the respective genes and reactions\n",
    "    reacs_in_model = missing_reacs[~(missing_reacs['add_to_GPR'].isnull())]\n",
    "    ncbiprot_with_reacs_in_model = [*chain(*list(reacs_in_model['ncbiprotein']))]\n",
    "    genes_with_reacs_in_model = missing_genes[missing_genes['ncbiprotein'].isin(ncbiprot_with_reacs_in_model)]\n",
    "    \n",
    "    if len(genes_with_reacs_in_model) > 0:\n",
    "        # add genes as gene products to model\n",
    "        add_genes_from_table(model, genes_with_reacs_in_model)\n",
    "    \n",
    "        # extend gene production rules \n",
    "        add_gene_reac_associations_from_table(model,reacs_in_model)\n",
    "        \n",
    "        # what remains:\n",
    "        missing_reacs = missing_reacs[missing_reacs['add_to_GPR'].isnull()]\n",
    "        missing_genes = missing_genes[~(missing_genes['ncbiprotein'].isin(ncbiprot_with_reacs_in_model))]\n",
    "    \n",
    "    \n",
    "    # Step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*chain(*list(mapped_res[1][~mapped_res[1]['add_to_GPR']]['ncbiprotein']))]\n",
    "testmodel = model.clone()\n",
    "# print(testmodel.getReaction('R_12DGR160tipp').getPlugin(0).getGeneProductAssociation().getListOfAllElements())\n",
    "testcase = mapped_res[1].copy()\n",
    "testcase.iloc[2,-1] = ['12DGR160tipp']\n",
    "fill_model(testmodel,mapped_res[0],testcase)\n",
    "after = testmodel.getPlugin(0).getListOfGeneProducts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G_WP_011274363_1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.getReaction('R_12DGR160tipp').getPlugin(0).getGeneProductAssociation().getListOfAllElements()[0].getGeneProduct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 MNXM1100221@MNXD1 + 1 MNXM735047@MNXD1 + 1 MNXM9@MNXD1 = 1 MNXM1100222@MNXD1 + 1 MNXM286@MNXD1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcase.iloc[2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further ideas and Code snippets for the filling part\n",
    "\n",
    "##### how to build the new entities:\n",
    "\n",
    "- option a) collection all information first, filter and then add them from table\n",
    "- option b) iteratively collection information and add entities (reaction after reaction)\n",
    "\n",
    "use libsbml or cobrapy?\n",
    "\n",
    "available functions:\n",
    "- libsbml-based create_reaction/create_species (needs all information beforehand + all other entities need to be in the model) -> required for the gene labels\n",
    "- cobra-based add_reaction/add_metabolite (builds as it goes), also match_id_to_namespace and \n",
    "finding possible matches might be easier using COBRApy <- namespace and annotation stuff far easier here\n",
    "\n",
    "definitly needed:\n",
    "- parse reaction string of different formats:\n",
    "    - MetaNetX (can get this somewhat from SPECIMEN)\n",
    "    - KEGG (also somewhat in SPECIMEN)\n",
    "    - BiGG (new?)\n",
    "    - BioCyc (new?)\n",
    "- retrieve needed information from the required databases (reaction/metabolites)\n",
    "    - cross referencing, if one db not enough?\n",
    "- filter for when to include reactions and when not (e.g. missing metabolites, formulas, DNA/RNA etc.) **This means, before adding stuff to the model, it needs to be validated**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload a libsbml model into a cobra model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tempfile._TemporaryFileWrapper object at 0x2c2110220>\n"
     ]
    }
   ],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "from refinegems.utility.io import write_model_to_file, load_model\n",
    "\n",
    "with NamedTemporaryFile(suffix='.xml') as tmp:\n",
    "    print(tmp)\n",
    "    write_model_to_file(model,tmp.name)\n",
    "    cobramodel = load_model(tmp.name,'cobra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse reaction string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C00024': 1.0, 'C00025': 1.0}, {'C00010': 1.0, 'C00624': 1.0}, None, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "equation = '1 MNXM1100221@MNXD1 + 1 MNXM735047@MNXD1 + 1 MNXM9@MNXD1 = 1 MNXM1100222@MNXD1 + 1 MNXM286@MNXD1'\n",
    "equation2 = 'aspsa_c + nadp_c + pi_c <-> 4pasp_c + h_c + nadph_c'\n",
    "equation3 = 'C00024 + C00025 <=> C00010 + C00624'\n",
    "\n",
    "# @TODO: BioCyc missing\n",
    "def parse_reac_str(equation, type='MetaNetX'):\n",
    "\n",
    "    products = {}\n",
    "    reactants = {}\n",
    "    compartments = list()\n",
    "    is_product = False\n",
    "    reversible = True\n",
    "\n",
    "    match type:\n",
    "        case 'MetaNetX':\n",
    "            for s in equation.split(' '):\n",
    "                # switch from reactants to products\n",
    "                if s == '=':\n",
    "                    is_product = True\n",
    "                # found stoichiometric factor\n",
    "                elif s.isnumeric():\n",
    "                    factor = float(s)\n",
    "                # skip\n",
    "                elif s == '+':\n",
    "                    continue\n",
    "                # found metabolite\n",
    "                else:\n",
    "                    # get information from MetaNetX\n",
    "                    metabolite, compartment = s.split('@')\n",
    "                    compartments.append(compartment)\n",
    "                    \n",
    "                    if is_product:\n",
    "                        products[metabolite] = factor\n",
    "                    else:\n",
    "                        reactants[metabolite] = factor\n",
    "                        \n",
    "        case 'BiGG':\n",
    "            factor = 1.0 # BiGG does not use factor 1 in the quations\n",
    "            for s in equation.split(' '):\n",
    "                # found factor\n",
    "                if s.isnumeric():\n",
    "                    factor = float(s)\n",
    "                # switch from reactants to products\n",
    "                elif s == '-->' :\n",
    "                    is_product = True\n",
    "                    reversible = False\n",
    "                elif s == '<->':\n",
    "                    is_product = True\n",
    "                # skip\n",
    "                elif s == '+':\n",
    "                    continue\n",
    "                # found metabolite\n",
    "                else:\n",
    "                    compartments.append(s.split('_')[1])\n",
    "                    if is_product:\n",
    "                        products[s] = factor\n",
    "                    else:\n",
    "                        reactants[s] = factor\n",
    "                    factor = 1.0\n",
    "              \n",
    "        case 'KEGG':\n",
    "            compartments = None\n",
    "            factor = 1.0\n",
    "            for s in equation.split(' '):\n",
    "                if s.isnumeric():\n",
    "                    factor = float(s)\n",
    "                elif s == '+':\n",
    "                    continue\n",
    "                elif s == '<=>': # @TODO are there more options?\n",
    "                    is_product = True\n",
    "                else:\n",
    "                    if is_product:\n",
    "                        products[s] = factor\n",
    "                    else:\n",
    "                        reactants[s] = factor\n",
    "                    factor = 1.0\n",
    "        \n",
    "        case 'BioCyc':\n",
    "            pass\n",
    "                  \n",
    "    return (reactants,products,compartments,reversible)\n",
    "        \n",
    "        \n",
    "        \n",
    "parse_reac_str(equation3,'KEGG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check, if a reaction should be added or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from SPECIMEN HQTB\n",
    "# @TODO\n",
    "def isreaction_complete(reac:cobra.Reaction, \n",
    "                        exclude_dna:bool=True, exclude_rna:bool=True) -> bool:\n",
    "\n",
    "    # check reaction\n",
    "    if exclude_dna and 'DNA' in reac.name:\n",
    "        return False\n",
    "    if exclude_rna and 'RNA' in reac.name:\n",
    "        return False\n",
    "\n",
    "    # check metabolites\n",
    "    for m in reac.metabolites:\n",
    "        if m.id == '' or pd.isnull(m.id):\n",
    "            return False\n",
    "        if m.name == '' or pd.isnull(m.name):\n",
    "            return False\n",
    "        if m.formula == '' or pd.isnull(m.formula):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "('MNXR104661',      ec-code       ncbiprotein          id  \\\n",
      "194  4.2.1.-  [WP_011274603.1]  MNXR104661   \n",
      "\n",
      "                                              equation     reference  \\\n",
      "194  1 MNXM505@MNXD1 + 1 WATER@MNXD1 = 1 MNXM988@MNXD1  keggR:R08766   \n",
      "\n",
      "    is_transport       via add_to_GPR  \n",
      "194         None  MetaNetX       None  )\n"
     ]
    }
   ],
   "source": [
    "genes_to_add = pd.DataFrame(columns=['ncbiprotein','reaction'])\n",
    "# for every type of database\n",
    "for t in mapped_res[1].groupby('via'):\n",
    "    # for every unique ID per database\n",
    "    for g in t.groupby('id'):\n",
    "        # try to rebuild the reaction\n",
    "\n",
    "        # check, if reaction was build successfully\n",
    "        #\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some decorators\n",
    "def template(func):\n",
    "    def wrapper():\n",
    "        print('This function is a template for developers.\\nThis cannot be executed.')\n",
    "    return wrapper\n",
    "\n",
    "def implement(func):\n",
    "    def wrapper():\n",
    "        print('The current function is just a placeholder and will be implement in the fucture.')\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refinegems.utility.io import load_a_table_from_database\n",
    "from refinegems.utility.entities import create_random_id, match_id_to_namespace\n",
    "import cobra\n",
    "import pandas as pd\n",
    "from typing import Literal\n",
    "from Bio.KEGG import REST, Compound\n",
    "import urllib\n",
    "\n",
    "# @TODO : name is an issue\n",
    "def get_BiGG_metabs_annotation_via_dbid(metabolite, id, dbcol, compartment):\n",
    "    if not 'bigg.metabolite' in metabolite.annotation.keys():\n",
    "        bigg_search = load_a_table_from_database(\n",
    "            f'SELECT * FROM bigg_metabolites WHERE \\'{dbcol}\\' = \\'{id}\\'',\n",
    "            query=True)\n",
    "        if len(bigg_search) > 0:\n",
    "            metabolite.annotation['bigg.metabolite'] = [_ for _ in bigg_search['id'].tolist() if _.endswith(f'_{compartment}')]\n",
    "            if len(metabolite.annotation['bigg.metabolite']) == 0:\n",
    "                metabolite.annotation.pop('bigg.metabolite')\n",
    "\n",
    "\n",
    "def add_annotations_from_BiGG_metabs(metabolite:cobra.Metabolite):\n",
    "    if 'bigg.metabolite' in metabolite.annotation.keys():\n",
    "        bigg_information = load_a_table_from_database(\n",
    "            'SELECT * FROM bigg_metabolites WHERE id = \\'' + f'\\' OR id = \\''.join(metabolite.annotation['bigg.metabolite']) + '\\'',\n",
    "            query=True)\n",
    "        db_id_bigg = {'BioCyc':'biocyc', 'MetaNetX (MNX) Chemical':'metanetx.chemical','SEED Compound':'seed.compound','CHEBI':'chebi', 'KEGG Compound':'kegg.compound'}\n",
    "        for db in db_id_bigg:\n",
    "            info = list(set(bigg_information[db].dropna().to_list()))\n",
    "            if len(info) > 0:\n",
    "                info = ','.join(info)\n",
    "                info = [x.strip() for x in info.split(',')] # make sure all entries are a separate list object\n",
    "                if db_id_bigg[db] in metabolite.annotation.keys():\n",
    "                    metabolite.annotation[db_id_bigg[db]] = list(set(info + metabolite.annotation[db_id_bigg[db]]))\n",
    "                else:\n",
    "                    metabolite.annotation[db_id_bigg[db]] = info\n",
    "\n",
    "\n",
    "@template\n",
    "def build_metabolite_xxx(id:str, model:cobra.Model, \n",
    "                         namespace:str,\n",
    "                         compartment:str,\n",
    "                         idprefix:str) -> cobra.Metabolite: \n",
    "    # check if id in model\n",
    "    # get information via id\n",
    "    # collection formation in a new metabolite object\n",
    "    # add more annotations from other databases\n",
    "    # adjust namespace\n",
    "    # check model again for new namespace\n",
    "    pass\n",
    "\n",
    "# originally from SPECIMEN\n",
    "# @TODO some issues left\n",
    "# current version works on a couple of examples \n",
    "def build_metabolite_mnx(id: str, model:cobra.Model, \n",
    "                         namespace:str='BiGG',\n",
    "                         compartment:str='c',\n",
    "                         idprefix:str='refineGEMs') -> cobra.Metabolite | None:\n",
    "\n",
    "    # fast check if compound already in model\n",
    "    # ------------------------------------------\n",
    "    # step 1: check if MetaNetX ID in model\n",
    "    matches = [x.id for x in model.metabolites if 'metanetx.chemical' in x.annotation and x.annotation['metanetx.chemical']==id and x.compartment == compartment]\n",
    "\n",
    "    # step 2: if yes, retrieve metabolite from model\n",
    "        # case 1: multiple matches found\n",
    "    if len(matches) > 0:\n",
    "        if len(matches) > 1:\n",
    "            # ................\n",
    "            # @TODO what to do\n",
    "            # currently, just the forst one is taken\n",
    "            # ................\n",
    "            match = model.metabolites.get_by_id(matches[0])\n",
    "        #  case 2: only one match found\n",
    "        else:\n",
    "            match = model.metabolites.get_by_id(matches[0])\n",
    "\n",
    "        # step 3: add metabolite\n",
    "        return match\n",
    "\n",
    "    # if not, create new metabolite\n",
    "    # -----------------------------\n",
    "    metabolite_prop = load_a_table_from_database(f'SELECT * FROM mnx_chem_prop WHERE id = \\'{id}\\'')\n",
    "    metabolite_anno = load_a_table_from_database(f'SELECT * FROM mnx_chem_xref WHERE id = \\'{id}\\'')\n",
    "    if len(metabolite_prop) == 0: # cannot construct metabolite\n",
    "        return None\n",
    "    else:\n",
    "        \n",
    "        # step 1: create a random metabolite ID\n",
    "        new_metabolite = cobra.Metabolite(create_random_id(model, 'meta', idprefix)) \n",
    "\n",
    "        # step 2: add features\n",
    "        # --------------------\n",
    "        new_metabolite.formula = metabolite_prop['formula'].iloc[0]\n",
    "        new_metabolite.name = metabolite_prop['name'].iloc[0]\n",
    "        new_metabolite.charge = metabolite_prop['charge'].iloc[0]\n",
    "        new_metabolite.compartment = compartment\n",
    "\n",
    "        # step 3: add notes\n",
    "        # -----------------\n",
    "        new_metabolite.notes['created with'] = 'refineGEMs GapFiller, metanetx.chemical'\n",
    "\n",
    "        # step 4: add annotations\n",
    "        # -----------------------\n",
    "        # add SBOTerm\n",
    "        new_metabolite.annotation['sbo'] = 'SBO:0000247'\n",
    "        \n",
    "        # add information directly available from the mnx_chem_prop table \n",
    "        new_metabolite.annotation['metanetx.chemical'] = [metabolite_prop['id'].iloc[0]]\n",
    "        if not pd.isnull(metabolite_prop['InChIKey'].iloc[0]):\n",
    "            new_metabolite.annotation['inchikey'] = metabolite_prop['InChIKey'].iloc[0].split('=')[1]\n",
    "        \n",
    "        # get more annotation from the mnx_chem_xref table\n",
    "        for db in ['kegg.compound','metacyc.compound','seed.compound','bigg.metabolite','chebi']:\n",
    "            db_matches = metabolite_anno[metabolite_anno['source'].str.contains(db)]\n",
    "            if len(db_matches) > 0:\n",
    "                new_metabolite.annotation[db] = [m.split(':',1)[1] for m in db_matches['source'].tolist()]\n",
    "\n",
    "        # Cleanup BiGG annotations (MetaNetX only saves universal)\n",
    "        # @TODO : there is no guarantee, that the id with the specific compartment actually exists -> still do it? // kepp the universal id?\n",
    "        new_metabolite.annotation['bigg.metabolite'] = [_+'_'+compartment for _ in new_metabolite.annotation['bigg.metabolite']]\n",
    "        # if no BiGG was found in MetaNetX, try reverse search in BiGG\n",
    "        get_BiGG_metabs_annotation_via_dbid(new_metabolite, id, 'MetaNetX (MNX) Chemical', compartment)\n",
    "                \n",
    "        # add additional information from BiGG (if ID found)    \n",
    "        add_annotations_from_BiGG_metabs(new_metabolite)\n",
    "\n",
    "        # step 5: change ID according to namespace\n",
    "        # ----------------------------------------\n",
    "        match_id_to_namespace(new_metabolite,namespace)\n",
    "       \n",
    "        # step 6: re-check existence of ID in model\n",
    "        # -----------------------------------------\n",
    "        # @TODO : check complete annotations? \n",
    "        #        - or let those be covered by the duplicate check later on?\n",
    "        if new_metabolite.id in [_.id for _ in model.metabolites]:\n",
    "            return model.metabolites.get_by_id(new_metabolite.id)\n",
    "           \n",
    "    return new_metabolite\n",
    "\n",
    "\n",
    "# originally from SPECIMEN\n",
    "# @TODO some issues left\n",
    "# current version works on a couple of examples \n",
    "def build_metabolite_kegg(kegg_id:str, model:cobra.Model, \n",
    "                          namespace:Literal['BiGG']='BiGG', \n",
    "                          compartment:str='c',\n",
    "                          idprefix='refineGEMs') -> cobra.Metabolite | None:\n",
    "\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # fast check if compound already in model\n",
    "    # ---------------------------------------\n",
    "    # step 1: check via KEGG ID\n",
    "    matches = [x.id for x in model.metabolites if ('kegg.compound' in x.annotation and x.annotation['kegg.compound'] == kegg_id)]\n",
    "    if len(matches) > 0:\n",
    "        # step 2: model id --> metabolite object\n",
    "        #  case 1: multiple matches found\n",
    "        if len(matches) > 1:\n",
    "            # .......\n",
    "            # @TODO\n",
    "            # .......\n",
    "            match = model.metabolites.get_by_id(matches[0])\n",
    "        #  case 2: only one match found\n",
    "        else:\n",
    "            match = model.metabolites.get_by_id(matches[0])\n",
    "\n",
    "        # step 3: add metabolite\n",
    "        return match\n",
    "\n",
    "    # -----------------------------\n",
    "    # if not, create new metabolite\n",
    "    # -----------------------------\n",
    "    \n",
    "    # step 1: retrieve KEGG entry for compound\n",
    "    # ----------------------------------------\n",
    "    try:\n",
    "        kegg_handle = REST.kegg_get(kegg_id)\n",
    "        kegg_record = [r for r in Compound.parse(kegg_handle)][0]\n",
    "    except urllib.error.HTTPError:\n",
    "        warnings.warn(F'HTTPError: {kegg_id}')\n",
    "        return None\n",
    "    except ConnectionResetError:\n",
    "        warnings.warn(F'ConnectionResetError: {kegg_id}')\n",
    "        return None\n",
    "    except urllib.error.URLError:\n",
    "        warnings.warn(F'URLError: {kegg_id}')\n",
    "        return None\n",
    "\n",
    "    # step 2: create a random metabolite ID\n",
    "    # -------------------------------------\n",
    "    new_metabolite = cobra.Metabolite(create_random_id(model, 'meta',idprefix)) \n",
    "\n",
    "    # step 3: add features\n",
    "    # --------------------\n",
    "    # set name from KEGG and additionally use it as ID if there is none yet\n",
    "    if isinstance(kegg_record.name, list):\n",
    "        # @TODO : better way to choose a name than to just take the first entry???\n",
    "        new_metabolite.name = kegg_record.name[0]\n",
    "    else:\n",
    "        new_metabolite.name = kegg_record.name\n",
    "    # set compartment\n",
    "    new_metabolite.compartment = compartment\n",
    "    # set formula\n",
    "    new_metabolite.formula = kegg_record.formula\n",
    "\n",
    "    # step 4: add notes\n",
    "    # -----------------\n",
    "    new_metabolite.notes['created with'] = 'refineGEMs GapFiller, KEGG.compound'\n",
    "\n",
    "    # step 5: add annotations\n",
    "    # -----------------------\n",
    "    # add annotation from the KEGG entry\n",
    "    new_metabolite.annotation['kegg.compound'] = kegg_id\n",
    "    db_idtf = {'CAS':'cas','PubChem':'pubchem.compound','ChEBI':'chebi'}\n",
    "    for db,ids in kegg_record.dblinks:\n",
    "        if db in db_idtf:\n",
    "            new_metabolite.annotation[db_idtf[db]] = ids\n",
    "            \n",
    "    # add SBOTerm\n",
    "    new_metabolite.annotation['sbo'] = 'SBO:0000247'\n",
    "\n",
    "    # search for infos in MetaNetX\n",
    "    # @TODO, since the table are readily available at the database now\n",
    "    mnx_info = load_a_table_from_database(\n",
    "        f'SELECT * FROM mnx_chem_xref WHERE source = \\'kegg.compound:{kegg_id}\\'',\n",
    "        query=True\n",
    "    )\n",
    "    if len(mnx_info) > 0:\n",
    "        mnx_ids = list(set(mnx_info['id']))\n",
    "    # mapping is unambiguously\n",
    "    if len(mnx_ids) == 1:\n",
    "        mnx_info = load_a_table_from_database(\n",
    "        f'SELECT * FROM mnx_chem_prop WHERE id = \\'{mnx_ids[0]}\\'',\n",
    "        query=True\n",
    "        )\n",
    "        # add charge \n",
    "        new_metabolite.charge = mnx_info['charge'].iloc[0]\n",
    "        # add more annotations\n",
    "        new_metabolite.annotation['metanetx.chemical'] = [mnx_info['id'].iloc[0]]\n",
    "        if not pd.isnull(mnx_info['InChIKey'].iloc[0]):\n",
    "            new_metabolite.annotation['inchikey'] = mnx_info['InChIKey'].iloc[0].split('=')[1]\n",
    "        \n",
    "        # get more annotation from the mnx_chem_xref table \n",
    "        metabolite_anno = load_a_table_from_database(f'SELECT * FROM mnx_chem_xref WHERE id = \\'{mnx_info[\"id\"]}\\'')\n",
    "        for db in ['kegg.compound','metacyc.compound','seed.compound','bigg.metabolite','chebi']:\n",
    "            db_matches = metabolite_anno[metabolite_anno['source'].str.contains(db)]\n",
    "            if len(db_matches) > 0:\n",
    "                mnx_tmp = [m.split(':',1)[1] for m in db_matches['source'].tolist()]\n",
    "                if db in new_metabolite.annotation.keys():\n",
    "                    new_metabolite.annotation[db] = list(set(mnx_tmp)+set(new_metabolite.annotation[db]))\n",
    "                else:\n",
    "                    new_metabolite.annotation[db] = mnx_tmp\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "        # @TODO : how to handle multiple matches, e.g. getting charge will be complicated\n",
    "        \n",
    "    # Cleanup BiGG annotations (MetaNetX only saves universal)\n",
    "    # @TODO : there is no guarantee, that the id with the specific compartment actually exists -> still do it? // kepp the universal id?\n",
    "    if 'bigg.metabolite' in new_metabolite.annotation.keys():\n",
    "        new_metabolite.annotation['bigg.metabolite'] = [_+'_'+compartment for _ in new_metabolite.annotation['bigg.metabolite']]\n",
    "    \n",
    "    # if no BiGG ID, try reverse search\n",
    "    get_BiGG_metabs_annotation_via_dbid(new_metabolite, id, 'KEGG Compound', compartment)\n",
    "    \n",
    "    # search for annotations in BiGG\n",
    "    add_annotations_from_BiGG_metabs(new_metabolite)\n",
    "\n",
    "    # step 6: change ID according to namespace\n",
    "    # ----------------------------------------\n",
    "    match_id_to_namespace(new_metabolite,namespace)\n",
    "    \n",
    "    # step 7: re-check existence of ID in model\n",
    "    # -----------------------------------------\n",
    "    # @TODO : check complete annotations? \n",
    "    #        - or let those be covered by the duplicate check later on?\n",
    "    if new_metabolite.id in [_.id for _ in model.metabolites]:\n",
    "        return model.metabolites.get_by_id(new_metabolite.id)\n",
    "\n",
    "    return new_metabolite\n",
    "\n",
    "\n",
    "@implement\n",
    "def build_metatabolite_bigg(id:str, model:cobra.Model, \n",
    "                         namespace:str,\n",
    "                         compartment:str,\n",
    "                         idprefix:str) -> cobra.Metabolite: \n",
    "    pass\n",
    "\n",
    "@implement\n",
    "def build_metabolite_biocyc(id:str, model:cobra.Model, \n",
    "                         namespace:str,\n",
    "                         compartment:str,\n",
    "                         idprefix:str) -> cobra.Metabolite: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "# -----------------\n",
    "\n",
    "@template\n",
    "def build_reaction_xxx():\n",
    "    pass\n",
    "\n",
    "# @TEST (more) - tries some cases, in which it seems to work\n",
    "# @TODO\n",
    "def build_rection_mnx(id, model,\n",
    "                      reac_str:str = None,\n",
    "                      references:dict={},\n",
    "                      idprefix='refineGEMs',\n",
    "                      namespace:Literal['BiGG']='BiGG') -> cobra.Reaction | None:\n",
    "    \n",
    "    # ---------------------\n",
    "    # check, if ID in model\n",
    "    # ---------------------\n",
    "    matches_found = [_.id for _ in model.reactions if 'metanetx.reaction' in _.annotation.keys() and _.annotation['metanetx.reaction']==id]\n",
    "    if len(matches_found) > 0:\n",
    "        return matches_found\n",
    "    \n",
    "    # -----------------------------\n",
    "    # otherwise, build new reaction\n",
    "    # -----------------------------\n",
    "    \n",
    "    # get relevant part of table from database\n",
    "    mnx_reac_refs = load_a_table_from_database(\n",
    "        f'SELECT * FROM mnx_reac_xref WHERE id = \\'{id}\\'',\n",
    "        query=True)\n",
    "    mnx_reac_refs = mnx_reac_refs[~(mnx_reac_refs['description']=='secondary/obsolete/fantasy identifier')]\n",
    "    \n",
    "    # create reaction object\n",
    "    new_reac = cobra.Reaction(create_random_id(model,'reac',idprefix))\n",
    "    \n",
    "    # set name of reaction\n",
    "    name = ''\n",
    "    for desc in mnx_reac_refs['description']:\n",
    "        if '|' in desc: # entry has a name and an equation string\n",
    "            name = desc.split('|')[0]\n",
    "            break # one name is enough\n",
    "    new_reac.name = name \n",
    "    \n",
    "    # get metabolites\n",
    "    # ---------------\n",
    "    if reac_str:\n",
    "        pass\n",
    "    else:\n",
    "        mnx_reac_prop = load_a_table_from_database(\n",
    "                f'SELECT * FROM mnx_reac_prop WHERE id = \\'{id}\\'',\n",
    "                query=True)\n",
    "        reac_str = mnx_reac_prop['mnx_equation'][0]\n",
    "        if mnx_reac_prop['ec-code'][0]:\n",
    "            references['ec-code'] = mnx_reac_prop['ec-code'][0]\n",
    "        \n",
    "    reactants,products,comparts,rev = parse_reac_str(reac_str)\n",
    "    # ............................................................\n",
    "    # @TODO / Issue\n",
    "    #    reac_prop / mnx equation only saves generic compartments 1 and 2 (MNXD1 / MNXD2)\n",
    "    #    how to get the (correct) compartment?\n",
    "    #    current solution 1 -> c, 2 -> e\n",
    "    comparts = ['c' if _ == 'MNXD1' else 'e' for _ in comparts ]\n",
    "    # ............................................................\n",
    "    metabolites = {}\n",
    "    meta_counter = 0\n",
    "    \n",
    "    # reconstruct reactants\n",
    "    for id,factor in reactants.items():\n",
    "        tmp_meta = build_metabolite_mnx(id,model,\n",
    "                                        namespace,\n",
    "                                        comparts[meta_counter],idprefix)\n",
    "        if tmp_meta:\n",
    "            metabolites[tmp_meta] = -1*factor\n",
    "            meta_counter += 1\n",
    "        else:\n",
    "            return None # not able to build reaction successfully\n",
    "        \n",
    "    # reconstruct products\n",
    "    for id,factor in products.items():\n",
    "        tmp_meta = build_metabolite_mnx(id,model,\n",
    "                                        namespace,\n",
    "                                        comparts[meta_counter],idprefix)\n",
    "        if tmp_meta:\n",
    "            metabolites[tmp_meta] = factor\n",
    "            meta_counter += 1\n",
    "        else:\n",
    "            return None # not able to build reaction successfully\n",
    "        \n",
    "    # add metabolites to reaction\n",
    "    # @TODO: does it need some kind of try and error, if - for some highly unlikely reason - two newly generated ids are the same\n",
    "    new_reac.add_metabolites(metabolites)\n",
    "    \n",
    "    # set reversibility\n",
    "    if rev:\n",
    "        new_reac.bounds = (1000.0,1000.0)\n",
    "    else:\n",
    "        new_reac.bounds = (0.0,1000.0)\n",
    "        \n",
    "    # get annotations\n",
    "    # ---------------\n",
    "    # get more annotation from the mnx_reac_xref table\n",
    "    for db in ['bigg.reaction','kegg.reaction','seed.reaction','metacyc.reaction','rhea']:\n",
    "        db_matches = mnx_reac_refs[mnx_reac_refs['source'].str.contains(db)]\n",
    "        if len(db_matches) > 0:\n",
    "            new_reac.annotation[db] = [m.split(':',1)[1] for m in db_matches['source'].tolist()]\n",
    "            # update reactions direction, if MetaCyc has better information\n",
    "            if db == 'metacyc.reaction' and len(db_matches[db_matches['source'].str.contains('-->')]):\n",
    "                new_reac.bounds = (0.0,1000.0)\n",
    "    # add additional references from the parameter\n",
    "    for db,idlist in references.items():\n",
    "        if not isinstance(idlist,list):\n",
    "            idlist = [idlist]\n",
    "        if db in new_reac.annotation.keys():\n",
    "            new_reac.annotation[db] = list(set(new_reac.annotation[db]) + set(idlist))\n",
    "        else:\n",
    "            new_reac.annotation[db] = idlist\n",
    "\n",
    "    # add notes\n",
    "    # ---------\n",
    "    new_reac.notes['created with'] = 'refineGEMs GapFiller, MetaNetX'\n",
    "    \n",
    "    # match ID to namespace\n",
    "    # ---------------------\n",
    "    match_id_to_namespace(new_reac,namespace)\n",
    "    \n",
    "    return new_reac\n",
    "\n",
    "@implement\n",
    "def build_reaction_kegg(model, id:str=None, reac_str:str=None,\n",
    "                        references:dict={},\n",
    "                        idprefix='refineGEMs',\n",
    "                        namespace:Literal['BiGG']='BiGG'):\n",
    "    \n",
    "    # either reaction id or a reaction string needed for reconstruction\n",
    "    if not id and not reac_str:\n",
    "        return None # reconstruction not possible\n",
    "    \n",
    "    \n",
    "    if id:\n",
    "        # check, if reaction in model\n",
    "        \n",
    "        # retrieve information from KEGG\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    if reac_str:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        return None # reconstruction not possible\n",
    "    \n",
    "\n",
    "@implement\n",
    "def build_reaction_bigg():\n",
    "    pass\n",
    "\n",
    "@implement\n",
    "def build_reaction_biocyc():\n",
    "    pass\n",
    "\n",
    "@implement\n",
    "def build_reaction():\n",
    "    pass\n",
    "\n",
    "# GapFiller functions\n",
    "@implement\n",
    "def add_reactions_from_table():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'MNXR104661'\n",
    "mnx_reac_refs = load_a_table_from_database(\n",
    "    f'SELECT * FROM mnx_reac_xref WHERE id = \\'{id}\\'',\n",
    "    query=True)\n",
    "mnx_reac_refs = mnx_reac_refs[~(mnx_reac_refs['description']=='secondary/obsolete/fantasy identifier')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
