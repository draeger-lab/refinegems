{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build growth curves from data\n",
    "\n",
    "working space for GitHub Issue #127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/brune/Documents/20_Projects/01_sprg/growth-curves/invitro_growth/Growth_ODs_plate1.tsv'\n",
    "filepath1 = '/Users/brune/Documents/20_Projects/01_sprg/growth-curves/invitro_growth/Growth_ODs_plate2.tsv'\n",
    "filepath2 = '/Users/brune/Documents/20_Projects/01_sprg/growth-curves/invitro_growth/Growth_ODs_plate3.tsv'\n",
    "filepaths = [filepath,filepath1,filepath2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue:\n",
    "\n",
    "reading in different formats can be very difficult - maybe set some guidelines on how to use this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_info(df):\n",
    "    test_info = dict()\n",
    "    blanks = dict()\n",
    "    test_cell = df.columns[1:]\n",
    "    used_medium = df.iloc[0,1:]\n",
    "    tested_strain = df.iloc[1,1:]\n",
    "    for t,m,s in zip(test_cell,used_medium,tested_strain):\n",
    "        if 'blank' == s:\n",
    "            if m in blanks.keys():\n",
    "                blanks[m].append(t)\n",
    "            else:\n",
    "                blanks[m] = [t]\n",
    "        else:\n",
    "            temp = str(m)+'_'+str(s)\n",
    "            if temp in test_info.keys():\n",
    "                test_info[temp].append(t) \n",
    "            else:\n",
    "                test_info[temp] = [t]\n",
    "    return test_info,blanks\n",
    "\n",
    "\n",
    "def convert_table(df, timeinterval=15):\n",
    "\n",
    "    # drop unneeded columns\n",
    "    df.drop(df.columns[2],axis=1,inplace=True) # drop temperature\n",
    "    df.drop(df.columns[0],axis=1,inplace=True) # drop first column\n",
    "\n",
    "    # extract cell information\n",
    "    info,blanks = extract_test_info(df)\n",
    "\n",
    "    # drop extracted information\n",
    "    df.drop(df.index[0],axis=0,inplace=True) \n",
    "    df.drop(df.index[0],axis=0,inplace=True)\n",
    "\n",
    "    # adjust time \n",
    "    timecol = [timeinterval*_ for _ in range(0,len(df.index),1)]\n",
    "    df.index = timecol\n",
    "    df.drop(df.columns[0],axis=1,inplace=True)\n",
    "\n",
    "    # calculate mean of blanks\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    for btype,blist in blanks.items():\n",
    "        df[btype] = df[blist].mean(axis=1)\n",
    "        df.drop(blist,axis=1,inplace=True)\n",
    "\n",
    "    # baseline correction\n",
    "    for condition,positions in info.items():\n",
    "        m = condition.split('_')[0]\n",
    "        for p in positions:\n",
    "            df[p] = df[p]-df[m]\n",
    "\n",
    "    # remove blanks\n",
    "    df.drop(blanks.keys(),axis=1,inplace=True)\n",
    "\n",
    "    return df,info\n",
    "\n",
    "def read_in_experiments(filepaths, timeinterval=15, skiprows=51):  # maybe kwargs for read_csv\n",
    "\n",
    "    info = dict()\n",
    "    data = 0\n",
    "\n",
    "    # read in all test data\n",
    "    for idx in range(0,len(filepaths)):\n",
    "        # read in the new table\n",
    "        current = pd.read_csv(filepath, sep='\\t', skiprows=skiprows)\n",
    "        suffix = str(idx)\n",
    "        current.rename(columns={c:c+'_'+suffix for c in list(current.columns)}, inplace=True)\n",
    "        # covert table into correct format + baseline correction\n",
    "        current_data,current_info = convert_table(current,timeinterval)\n",
    "        # concat data\n",
    "        if isinstance(data,pd.DataFrame):\n",
    "            for k,v in current_info.items():\n",
    "                if k in info.keys():\n",
    "                    info[k] = info[k]+current_info[k]\n",
    "                else:\n",
    "                    # Should not happen - maybe print a warning?\n",
    "                    info[k] = current_info\n",
    "            data = pd.concat([data,current_data],axis=1)\n",
    "        else:\n",
    "            info = current_info\n",
    "            data = current_data\n",
    "\n",
    "    return data,info\n",
    "\n",
    "def calculate_bio_mean(data_table, data_info):\n",
    "\n",
    "    means = dict()\n",
    "    stdevs = dict()\n",
    "\n",
    "    # calculate the mean over the replicates\n",
    "    for condition,positions in data_info.items():\n",
    "        means[condition] = data_table[positions].mean(axis=1)\n",
    "        stdevs[condition] = data_table[positions].std(axis=1)\n",
    "\n",
    "    means = pd.DataFrame(means)\n",
    "    stdevs = pd.DataFrame(stdevs)\n",
    "\n",
    "    return means,stdevs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,info = read_in_experiments(filepaths)\n",
    "dmean, dstd = calculate_bio_mean(data,info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gompertz_model(t,a,b,c): #based on Franses94\n",
    "    return a*np.exp(-b*np.exp(-c*t))\n",
    "\n",
    "def fourparam_gompertz_model(t,a,b,ku,ti): \n",
    "    return b+((a-b)*np.exp(-np.exp(-ku*(t-ti))))\n",
    "\n",
    "def logistic_mod(t, K, N0, r): #asadi2020\n",
    "    return K/(1+((K-N0)/N0)*np.exp(-r*t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_growth_curve(dmean,dstd,fit,col,perc=None):\n",
    "\n",
    "    # idea:\n",
    "    # get indx at max \n",
    "    # get index at first position with condition idx > idx_max & value < x% max\n",
    "    # only take values with values smaller than the idx calculated above \n",
    "    # (if result else take all)\n",
    "\n",
    "    xdata = dmean.index\n",
    "    ydata = dmean.iloc[:,col]\n",
    "    errdata = dstd.iloc[:,col]\n",
    "    cutoff = None\n",
    "    if perc:\n",
    "        max_point = (dmean.iloc[:,col].idxmax(), dmean.iloc[:,col].max())\n",
    "        temp = dmean.iloc[:,col][(dmean.index > max_point[0]) & (dmean.iloc[:,col] < perc*max_point[1])]\n",
    "        if len(temp) > 0:\n",
    "            cutoff = temp.index[0]\n",
    "            xdata = dmean.index[dmean.index < cutoff]\n",
    "            ydata = dmean.iloc[dmean.index < cutoff,col]\n",
    "            errdata = dstd.iloc[dmean.index < cutoff,col]        \n",
    "\n",
    "    match fit:\n",
    "\n",
    "        case 'gompertz4':\n",
    "            solution = curve_fit(fourparam_gompertz_model, xdata, \n",
    "                                 ydata, sigma=errdata, method='lm', \n",
    "                                 p0=np.asarray([0.2,0.005,0.05,0.05])) #p0=np.asarray([0.2,0.005,0.05,30]) \n",
    "\n",
    "        case 'logistic':\n",
    "            solution = curve_fit(logistic_mod, xdata, ydata, \n",
    "                                 sigma=errdata, method='lm', \n",
    "                                 p0=np.asarray([0.2,0.005,0.05])) #p0=np.asarray([0.2,0.005,0.05,30]) \n",
    "\n",
    "    return cutoff,solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_growth_curves(dmean,dstd,solu, cutoff, col, fit):\n",
    "\n",
    "    # plot the mean data points\n",
    "    plt.scatter(x=list(dmean.index),\n",
    "                y=list(dmean.iloc[:,col]),\n",
    "                marker='.'\n",
    "                )\n",
    "    # plots the error bars\n",
    "    plt.errorbar(x=list(dmean.index),\n",
    "                y=list(dmean.iloc[:,col]),\n",
    "                xerr=dstd.iloc[:,col],\n",
    "                yerr=dstd.iloc[:,col],\n",
    "                fmt='none',\n",
    "                alpha=0.5\n",
    "                )\n",
    "    \n",
    "    # filter data for fit, if cutoff was set\n",
    "    if cutoff:\n",
    "        xdata = list(dmean.index[dmean.index < cutoff])\n",
    "    else:\n",
    "        xdata = list(dmean.index)\n",
    "\n",
    "    # visualise the fit\n",
    "    match fit:\n",
    "        \n",
    "        case 'gompertz4':\n",
    "            plt.plot(xdata,\n",
    "                     [fourparam_gompertz_model(point,solu[0][0],solu[0][1],solu[0][2],solu[0][3]) for point in xdata],\n",
    "                    color='red')\n",
    "            \n",
    "        case 'logistic':\n",
    "            plt.plot(xdata,\n",
    "                     [logistic_mod(point,solu[0][0],solu[0][1],solu[0][2]) for point in xdata],\n",
    "                    color='red')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### issues \n",
    "\n",
    "- RuntimeError / starting values leading to very different values \n",
    "\n",
    "    - how to set good starting values\n",
    "    - how to deal with the RuntimeErrors (solution cannot be calculated)\n",
    "\n",
    "- bad/irregular data\n",
    "\n",
    "    - perc parameter for cutting of the end -> good idea or not and how to choose it and when to set it\n",
    "    - the different fits (currently implemented) can lead to VERY different results -> option to calculate the mean to even it out? What, if there are outliers? Which functions are more robust than other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Optimal parameters not found: Number of calls to function has reached maxfev = 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#fit = 'logistic'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgompertz4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m cut, solu \u001b[38;5;241m=\u001b[39m \u001b[43mfit_growth_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dmean\u001b[38;5;241m.\u001b[39mcolumns[x])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m(solu[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m, in \u001b[0;36mfit_growth_curve\u001b[0;34m(dmean, dstd, fit, col, perc)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m fit:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgompertz4\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m         solution \u001b[38;5;241m=\u001b[39m \u001b[43mcurve_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfourparam_gompertz_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mydata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mp0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#p0=np.asarray([0.2,0.005,0.05,30]) \u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     30\u001b[0m         solution \u001b[38;5;241m=\u001b[39m curve_fit(logistic_mod, xdata, ydata, \n\u001b[1;32m     31\u001b[0m                              sigma\u001b[38;5;241m=\u001b[39merrdata, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlm\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     32\u001b[0m                              p0\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.005\u001b[39m,\u001b[38;5;241m0.05\u001b[39m])) \u001b[38;5;66;03m#p0=np.asarray([0.2,0.005,0.05,30]) \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sprg/lib/python3.10/site-packages/scipy/optimize/_minpack_py.py:982\u001b[0m, in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m     cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(infodict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfvec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m--> 982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal parameters not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m errmsg)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Rename maxfev (leastsq) to max_nfev (least_squares), if specified.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_nfev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Optimal parameters not found: Number of calls to function has reached maxfev = 1000."
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "#fit = 'logistic'\n",
    "fit = 'gompertz4'\n",
    "cut, solu = fit_growth_curve(dmean,dstd,fit,x,80)\n",
    "print(dmean.columns[x])\n",
    "print(np.log(2)/(solu[0][2]))\n",
    "plot_growth_curves(dmean,dstd,solu,cut,x,fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
