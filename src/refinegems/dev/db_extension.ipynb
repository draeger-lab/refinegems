{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code & example to update refineGEMs' internal database\n",
    "The following code transforms a human-readable TSV file in the FILE_DIRECTORY (I) into the data format required to update the internal database of refineGEMs (II & III)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gusak/miniconda3/envs/refineGEMs310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/gusak/miniconda3/envs/refineGEMs310/lib/python3.10/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from refinegems.medium import update_db_multi, updated_db_to_schema\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ntpath\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (I) File directory\n",
    "The file directory needs to be specified here. All files from this directory will be used to generate new TSV files compatible with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIRECTORY = '../../../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (II) Transformation of human-readable TSV files to database-readable files\n",
    "The following function `transform_medium_tsv_table_for_update` does the main job in transforming the TSV files into database-readable TSV files. </br>\n",
    "This function is currently only setting up the input for the database tables 'medium2substance' and 'substance2db'. </br>\n",
    "The code cell underneath the function definition cell specifies that only files ending with '_substances.tsv' should be transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_medium_tsv_tables_for_update(table_path: str, file_directory: str):\n",
    "   \"\"\"Transforms a TSV table containing a medium definition into a TSV file(s) usable \n",
    "   with the medium.py setup to be used to automatically update the database\n",
    "\n",
    "   Args:\n",
    "       - table_path (str): Path to the TSV file defining a medium\n",
    "       - file_directory (str): Path to the current workspace directory\n",
    "   \"\"\"\n",
    "   # Get medium name & DataFrame\n",
    "   medium_name_list = ntpath.basename(table_path).split('_')\n",
    "   medium_name = medium_name_list[0]\n",
    "   if medium_name_list[1] in ['medium', 'subset']: medium_name += f'_{medium_name_list[1]}'\n",
    "   medium_df = pd.read_csv(table_path, sep='\\t')\n",
    "   \n",
    "   # Rename relevant & drop unnecessary columns\n",
    "   medium_df.drop(['flux', 'formula'], axis=1, inplace=True)\n",
    "   medium_df.rename({'name': 'substance'}, axis=1, inplace=True)\n",
    "   \n",
    "   ### Get the m2s table for update\n",
    "   m2s_df = medium_df[['substance', 'source']].copy()\n",
    "   \n",
    "   # Rename 'source' to 'new_value'\n",
    "   m2s_df.rename({'source': 'new_value'}, axis=1, inplace=True)\n",
    "   \n",
    "   # Add new columns medium, table & column to m2s table\n",
    "   m2s_df['medium'] = medium_name\n",
    "   m2s_df['table'] = 'medium2substance'\n",
    "   m2s_df['column'] = 'source'\n",
    "   \n",
    "   # Add conditions column to m2s table\n",
    "   m2s_df['conditions'] = m2s_df.apply(lambda row: f'substance={row[\"substance\"]};medium={row[\"medium\"]}', axis=1)\n",
    "   m2s_df.drop(['substance', 'medium'], axis=1, inplace=True)\n",
    "   \n",
    "   # Extract m2s table\n",
    "   m2s_df.to_csv(f'{file_directory}{medium_name}_substances_for_m2s_update.tsv', sep='\\t', index=False)\n",
    "   \n",
    "   if len(medium_df.columns) > 4:\n",
    "      ### Get the s2db table for update, if possible\n",
    "      s2db_df = medium_df.drop('source', axis=1)\n",
    "      \n",
    "      # Merge VMH & BiGG if they have the same ID & Column does not already exist\n",
    "      if not 'BiGG+VMH' in s2db_df.columns:\n",
    "         # Create new column 'BiGG+VMH'\n",
    "         s2db_df['BiGG+VMH'] = np.NaN\n",
    "         \n",
    "         # Merge VMH & BiGG column for same IDs & Remove original entries\n",
    "         def merge_BiGG_VMH(row: pd.Series):\n",
    "            if (row['BiGG'] == (row['VMH'])): # | (row[\"BiGG\"].isna() & row[\"VMH\"].isna())\n",
    "               row['BiGG+VMH'] = row['BiGG']\n",
    "               row['BiGG'] = np.NaN # Remove entry from column\n",
    "               row['VMH'] = np.NaN # Remove entry from column\n",
    "            else:\n",
    "               row['BiGG+VMH'] = np.NaN\n",
    "            return row\n",
    "      \n",
    "         s2db_df = s2db_df.apply(merge_BiGG_VMH, axis=1)\n",
    "      \n",
    "      # Transform table into long format\n",
    "      s2db_df = pd.melt(s2db_df, id_vars='substance', var_name='db_type', value_name='db_id', ignore_index=True)\n",
    "      \n",
    "      # Remove all NaNs\n",
    "      s2db_df.dropna(inplace=True)\n",
    "      \n",
    "      # Add new columns table & column to s2db table\n",
    "      s2db_df['table'] = 'substance2db'\n",
    "      s2db_df['column'] = 'substance_id, db_id, db_type'\n",
    "      \n",
    "      # Create 'new_value' from 'db_type' & 'db_id'\n",
    "      s2db_df['new_value'] = s2db_df.apply(lambda row: f'{row[\"db_id\"]}, {row[\"db_type\"]}', axis=1)\n",
    "      s2db_df.drop(['db_type', 'db_id'], axis=1, inplace=True)\n",
    "      \n",
    "      # Add conditions column to s2db table\n",
    "      s2db_df['conditions'] = s2db_df.apply(lambda row: f'substance={row[\"substance\"]}', axis=1)\n",
    "      s2db_df.drop('substance', axis=1, inplace=True)\n",
    "      \n",
    "      # Extract s2db table\n",
    "      s2db_df.to_csv(f'{file_directory}{medium_name}_substances_for_s2db_update.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPMI_substances.tsv\n",
      "CasA_subset_substances.tsv\n",
      "CGXII_substances.tsv\n",
      "dGMM_substances.tsv\n",
      "M9_substances.tsv\n",
      "CasA_medium_substances.tsv\n",
      "MP-AU_substances.tsv\n",
      "SNM3_substances.tsv\n",
      "LB_substances.tsv\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(FILE_DIRECTORY):\n",
    "    if files.endswith('_substances.tsv'):\n",
    "        if 'already' in files: continue\n",
    "        print(files)\n",
    "        transform_medium_tsv_tables_for_update(f'{FILE_DIRECTORY}{files}', FILE_DIRECTORY)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (III) Add data from the database-readable TSV file to the database\n",
    "The following code iterates over all newly generated TSV files and updates the database tables 'medium2substance' and 'substance2db' accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CasA_subset_substances_for_s2db_update.tsv\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=cpd00395, SEED, condition=substance=L-Cysteate\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=MNXM713, MetaNetX, condition=substance=L-Cysteate\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=Lcyst, BiGG+VMH, condition=substance=L-Cysteate\n",
      "CasA_medium_substances_for_m2s_update.tsv\n",
      "RPMI_substances_for_m2s_update.tsv\n",
      "SNM3_substances_for_m2s_update.tsv\n",
      "MP-AU_substances_for_m2s_update.tsv\n",
      "CGXII_substances_for_m2s_update.tsv\n",
      "M9_substances_for_m2s_update.tsv\n",
      "CasA_subset_substances_for_m2s_update.tsv\n",
      "CGXII_substances_for_s2db_update.tsv\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value= oh1, BiGG+VMH, condition=substance=Hydroxide\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=cpd15275, SEED, condition=substance=Hydroxide\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=MNXM02, MetaNetX, condition=substance=Hydroxide\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=C01328, KEGG, condition=substance=Hydroxide\n",
      "dGMM_substances_for_m2s_update.tsv\n",
      "dGMM_substances_for_s2db_update.tsv\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=cpd24344, SEED, condition=substance=Aluminium(III) cation [Al(3+)]\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=cpd11640, SEED, condition=substance=Dihydrogen [H2]\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=MNXM729498, MetaNetX, condition=substance=Aluminium(III) cation [Al(3+)]\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=MNXM1108018, MetaNetX, condition=substance=Dihydrogen [H2]\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=h2, BiGG+VMH, condition=substance=Dihydrogen [H2]\n",
      "LB_substances_for_m2s_update.tsv\n",
      "CasA_medium_substances_for_s2db_update.tsv\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=Lcyst, BiGG+VMH, condition=substance=L-Cysteate\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=cpd00395, SEED, condition=substance=L-Cysteate\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=MNXM713, MetaNetX, condition=substance=L-Cysteate\n",
      "UNIQUE constraint failed: substance2db.substance_id, substance2db.db_id\n",
      "Ocurred with: column=substance_id, db_id, db_type, new_value=C00506, KEGG, condition=substance=L-Cysteate\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(FILE_DIRECTORY):\n",
    "    if files.endswith('_update.tsv'):\n",
    "            print(files)\n",
    "            update = True if 'm2s' in files else False\n",
    "            df = pd.read_csv(f'{FILE_DIRECTORY}{files}', sep='\\t')\n",
    "            update_db_multi(df, update_entries=update)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Schema with updated database\n",
    "!Be careful to  check the changes between the current SQL Schema file and the new one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_db_to_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refineGEMs310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
